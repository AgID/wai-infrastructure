# Environment name
environment = "production"
environment_short = "prod"

# K8S network CIDR
k8s_network_cidr = "<K8S_CIDR>"

# K8S master instance parameters
k8s_master_instance = {
    image_id = "<IMAGE_ID>"
    flavor_id = "<FLAVOR_ID>"
    num_instances = <NUM_OF_INSTANCES>
    boot_volume_size = <VOLUME_SIZE>
    boot_volume_type = <VOLUME_TYPE>
    data_volume_size = <VOLUME_SIZE>
    data_volume_type = <VOLUME_TYPE>
}

# K8S master instance groups added to metadata for ansible dynamic inventory
# Each item in the list will be added to the corresponding instance number
# i.e. the first item in the list will be added to the first instance and so on
# if there are more instances than items in the list it will restart from the first one
k8s_master_instance_groups = ["kube-master, etcd"]

# K8S master security group rules
# See https://kubernetes.io/docs/setup/independent/install-kubeadm/#check-required-ports
k8s_master_sec_rules = [
    {
        protocol = "icmp"
        from = 0
        to = 0
        cidr = "<CIDR>"
    },
    {
        protocol = "tcp"
        from = 22
        to = 22
        cidr = "<CIDR>"
    },
    {
        protocol = "tcp"
        from = 6443
        to = 6443
        cidr = "<CIDR>"
    },
    {
        protocol = "tcp"
        from = 2379
        to = 2380
        cidr = "<K8S_CIDR>"
    },
    {
        protocol = "tcp"
        from = 10250
        to = 10250
        cidr = "<K8S_CIDR>"
    },
    # See https://www.weave.works/docs/net/latest/install/using-weave/#creating-peer-connections-between-hosts
    {
        protocol = "tcp"
        from = 6783
        to = 6783
        cidr = "<K8S_CIDR>"
    },
    {
        protocol = "udp"
        from = 6783
        to = 6784
        cidr = "<K8S_CIDR>"
    },
    # Prometheus node exporter
    {
        protocol = "tcp"
        from = 9100
        to = 9100
        cidr = "<K8S_CIDR>"
    }
]

# K8S master assigned floating IPs (uncomment if needed)
#k8s_master_floatingips = [<FLOATING_IP_1>, <FLOATING_IP_2>, ...]

# K8S worker instance parameters
k8s_worker_instance = {
    image_id = "<IMAGE_ID>"
    flavor_id = "<FLAVOR_ID>"
    num_instances = <NUM_OF_INSTANCES>
    boot_volume_size = <VOLUME_SIZE>
    boot_volume_type = <VOLUME_TYPE>
    data_volume_size = <VOLUME_SIZE>
    data_volume_type = <VOLUME_TYPE>
}

# K8S worker instance groups added to metadata for ansible dynamic inventory
# Each item in the list will be added to the corresponding instance number
# i.e. the first item in the list will be added to the first instance and so on
# if there are more instances than items in the list it will restart from the first one
k8s_worker_instance_groups = ["kube-node"]

# K8S worker security rules
# See https://kubernetes.io/docs/setup/independent/install-kubeadm/#check-required-ports
k8s_worker_sec_rules = [
    {
        protocol = "icmp"
        from = 0
        to = 0
        cidr = "<CIDR>"
    },
    {
        protocol = "tcp"
        from = 22
        to = 22
        cidr = "<CIDR>"
    },
    # Allow http/https traffic since nginx ingress controller is publicy exposed via MetalLB
    {
        protocol = "tcp"
        from = 80
        to = 80
        cidr = "0.0.0.0/0"
    },
    {
        protocol = "tcp"
        from = 443
        to = 443
        cidr = "0.0.0.0/0"
    },
    # change to cidr = "0.0.0.0/0" if you expose services via NodePort publicly
    {
        protocol = "tcp"
        from = 30000
        to = 32767
        cidr = "<K8S_CIDR>"
    },
    {
        protocol = "tcp"
        from = 10250
        to = 10250
        cidr = "<K8S_CIDR>"
    },
    # See https://www.weave.works/docs/net/latest/install/using-weave/#creating-peer-connections-between-hosts
    {
        protocol = "tcp"
        from = 6783
        to = 6783
        cidr = "<K8S_CIDR>"
    },
    {
        protocol = "udp"
        from = 6783
        to = 6784
        cidr = "<K8S_CIDR>"
    },
    # Prometheus node exporter
    {
        protocol = "tcp"
        from = 9100
        to = 9100
        cidr = "<K8S_CIDR>"
    }
]

# K8S worker assigned floating IPs  (uncomment if needed)
#k8s_master_floatingips = [<FLOATING_IP_1>, <FLOATING_IP_2>, ...]

# Galera slug name
galera_slug = "galera"

# Galera network CIDR
galera_network_cidr = "<GALERA_CIDR>"

# Galera instance parameters
galera_instance = {
    image_id = "<IMAGE_ID>"
    flavor_id = "<FLAVOR_ID>"
    num_instances = <NUM_OF_INSTANCES>
    boot_volume_size = <VOLUME_SIZE>
    boot_volume_type = <VOLUME_TYPE>
    data_volume_size = <VOLUME_SIZE>
    data_volume_type = <VOLUME_TYPE>
}

# Galera instance groups added to metadata for ansible dynamic inventory
# Each item in the list will be added to the corresponding instance number
# i.e. the first item in the list will be added to the first instance and so on
# if there are more instances than items in the list it will restart from the first one
galera_instance_groups = ["galera-prod", "galera-prod", "galera-prod", "galera-prod-slave", "galera-prod-slave", "galera-prod-slave"]

# Galera security rules
# See http://galeracluster.com/documentation-webpages/firewallsettings.html
galera_sec_rules = [
    {
        protocol = "icmp"
        from = 0
        to = 0
        cidr = "<CIDR>"
    },
    {
        protocol = "tcp"
        from = 22
        to = 22
        cidr = "<CIDR>"
    },
    {
        protocol = "tcp"
        from = 3306
        to = 3306
        cidr = "<CIDR>"
    },
    {
        protocol = "tcp"
        from = 4567
        to = 4567
        cidr = "<GALERA_CIDR>"
    },
    {
        protocol = "udp"
        from = 4567
        to = 4567
        cidr = "<GALERA_CIDR>"
    },
    {
        protocol = "tcp"
        from = 4568
        to = 4568
        cidr = "<GALERA_CIDR>"
    },
    {
        protocol = "tcp"
        from = 4444
        to = 4444
        cidr = "<GALERA_CIDR>"
    },
    # Prometheus Node Exporter
    {
        protocol = "tcp"
        from = 9100
        to = 9100
        cidr = "<K8S_CIDR>"
    },
    # Prometheus MYSQLD Exporter
    {
        protocol = "tcp"
        from = 9104
        to = 9104
        cidr = "<K8S_CIDR>"
    }
]

# Elastic slug name
elastic_slug = "elastic"

# Elastic network CIDR
elastic_network_cidr = "<ELASTIC_CIDR>"

# Elastic instance parameters
elastic_instance = {
    image_id = "<IMAGE_ID>"
    flavor_id = "<FLAVOR_ID>"
    num_instances = <NUM_OF_INSTANCES>
    boot_volume_size = <VOLUME_SIZE>
    boot_volume_type = <VOLUME_TYPE>
    data_volume_size = <VOLUME_SIZE>
    data_volume_type = <VOLUME_TYPE>
}

# Elastic instance groups added to metadata for ansible dynamic inventory
# Each item in the list will be added to the corresponding instance number
# i.e. the first item in the list will be added to the first instance and so on
# if there are more instances than items in the list it will restart from the first one
elastic_instance_groups = ["elastic", "elastic", "elastic, kibana"]

# Elastic security rules
# See https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-network.html
# and https://www.elastic.co/guide/en/kibana/current/settings.html
elastic_sec_rules = [
    {
        protocol = "icmp"
        from = 0
        to = 0
        cidr = "<CIDR>"
    },
    {
        protocol = "tcp"
        from = 22
        to = 22
        cidr = "<CIDR>"
    },
    {
        protocol = "tcp"
        from = 9200
        to = 9200
        cidr = "<CIDR>"
    },
    {
        protocol = "tcp"
        from = 9300
        to = 9300
        cidr = "<ELASTIC_CIDR>"
    },
    {
        protocol = "tcp"
        from = 5601
        to = 5601
        cidr = "<CIDR>"
    },
    # Prometheus Node Exporter
    {
        protocol = "tcp"
        from = 9100
        to = 9100
        cidr = "<K8S_CIDR>"
    }
]

# Gluster slug name
gluster_slug = "gluster"

# Gluster network CIDR
gluster_network_cidr = "<GLUSTER_CIDR>"

# Gluster instance parameters
gluster_instance = {
    image_id = "<IMAGE_ID>"
    flavor_id = "<FLAVOR_ID>"
    num_instances = <NUM_OF_INSTANCES>
    boot_volume_size = <VOLUME_SIZE>
    boot_volume_type = <VOLUME_TYPE>
    data_volume_size = <VOLUME_SIZE>
    data_volume_type = <VOLUME_TYPE>
}

# Gluster instance groups added to metadata for ansible dynamic inventory
# Each item in the list will be added to the corresponding instance number
# i.e. the first item in the list will be added to the first instance and so on
# if there are more instances than items in the list it will restart from the first one
gluster_instance_groups = ["gluster"]

# Gluster security rules
# See https://docs.gluster.org/en/latest/Administrator%20Guide/Setting%20Up%20Clients/
gluster_sec_rules = [
    {
        protocol = "icmp"
        from = 0
        to = 0
        cidr = "<CIDR>"
    },
    {
        protocol = "tcp"
        from = 22
        to = 22
        cidr = "<CIDR>"
    },
    {
        protocol = "tcp"
        from = 24007
        to = 24008
        cidr = "<GLUSTER_CIDR>"
    },
    {
        protocol = "udp"
        from = 24007
        to = 24008
        cidr = "<GLUSTER_CIDR>"
    },
    {
        protocol = "tcp"
        from = 49152
        to = 49162
        cidr = "<GLUSTER_CIDR>"
    },
    # Heketi
    {
        protocol = "tcp"
        from = 8080
        to = 8080
        cidr = "<K8S_CIDR>"
    },
    # Prometheus Node Exporter
    {
        protocol = "tcp"
        from = 9100
        to = 9100
        cidr = "<K8S_CIDR>"
    }
]
